необходимо реализовать проект
1. распознавание рисков сельхоз культур по фотографиям
2. в папке crawler лежат данные по рискам в файлах csv
3. нужно сделать crawler который по аннным рисков соберет картинки по болезням, которые будут собраны в папке crawler/download/images/
4. необходимо реализовать код, который сходит в гугл gemini
https://ai.google.dev/gemini-api/docs/image-understanding?hl=ru
и по маркированным картинкам начнет распознавать риски
для gemini распиши стоимость и способы обучения и верефикации модели
5. необходимо сделать механизм разметки и подготовки датасета для обучения yolov11. Используй при недостатке картинок stableDefusion
6. обучения с помощью yolov11 с фиксацией результатов обучения в `wandb` с возможностью просмотра
7. нужно реализовать хранение версий моделей в minio
8. сформируй модуль дообучения моделей с поиском оптимальніх гиперпараметров
9. Сформируй код для triton либо ray для контроля inference
10. сформируй fastAPI бекенд и веб приложение на gradio, которое реализует передачу фото в gemini и в локальную модель выдаст сравнение результатов. На все сервера ниже должні біть переході, чтобі получить доступ к веб ресурсам работі с данніми и моделями
11. Сформируй механизм дообучения и inference модели yololv11 в dagster используй assets для работы с моделью и переобучением
12. Write code for detecting drift in your pipeline Dagster) within your input and output features

13. в результате сделай документ который опишет проект по блокам, порядок работы с ним. Документ должен быть описан на украинском языке

Каждый значимый раздел выделяй в отдельную папку с модулями
версия python 3.12
библиотеки максимальных версий



#### 2. Основні розділи проекту
##### 2.1 crawler
**Завдання:** Збір та організація даних по ризикам та автоматичне скачування зображень ознак хвороб.
- Зчитування даних з CSV.
- Складання запитів та автоматичне скачування зображень із пошукових сервісів.
- Збереження зображень у `crawler/download/images/`.

##### 2.2 dataset-labeling
**Завдання:** Бізнес-логіка для ручної (інтерфейс) та автоматичної розмітки зображень:
- Розмітка з використанням інструментів для bounding boxes або segmentation.
- За потреби — генерація додаткових даних через Stable Diffusion.

##### 2.3 gemini-integration
**Завдання:** Взаємодія з Google Gemini API для розпізнавання ризиків по зображенню.
- Вартість: Google Gemini має decoupled тарифи, залежні від кількості запитів та обсягу даних. Деталі: [Google Gemini Pricing](https://ai.google.dev/gemini-api/docs/pricing).
- Навчання: Використовується zero-shot/one-shot learning, надається зразок або невеликий датасет.
- Верифікація: Через реальний запуск inference та порівняння результатів із ground truth.

##### 2.4 yolov11-train
**Завдання:** Підготовка та навчання YOLOv11:
- Підготовка датасету.
- Тренування з фіксацією результатів у Weights & Biases (`wandb`).
- Автоматичний пошук оптимальних гіперпараметрів (наприклад, Optuna).

##### 2.5 minio-storage
**Завдання:** Організація зберігання версій моделей у MinIO.
- Збереження, версіонування, отримання моделей.

##### 2.6 triton-inference / ray-inference
**Завдання:** Сервер для inference з контролем навантаження та масштабування.
- Може бути реалізовано на Triton або Ray Serve.
- Моніторинг speed/latency/accuracy.

##### 2.7 backend (fastAPI)
**Завдання:** API для взаємодії із зовнішніми сервісами та фронтендом.
##### 2.8 gradio-web
**Завдання:** Веб-інтерфейс для завантаження фотографій, отримання результатів з локальної моделі YOLOv11 та Gemini, а також порівняння результатів.
##### 2.9 dagster-pipeline
**Завдання:** Реалізація пайплайну в Dagster:
- Ассетна архітектура під навчання, донавчання, inference YOLOv11.
- Виявлення дріфта у вхідних та вихідних даних.
- Протоколювання всіх етапів.

#### 3. Порядок роботи з проектом
1. **crawler**
    - Запустіть crawler для агрегації базових CSV із ризиками та скачування зображень.

2. **dataset-labeling**
    - Використовуйте захардкоджений/напівавтоматичний механізм розмітки.
    - За недостатності даних — автоматична генерація даних у Stable Diffusion.

3. **gemini-integration**
    - Зробіть API-інтеграцію Gemini.
    - Проведіть тестування якості/вартість/latency зображень.

4. **yolov11-train**
    - Створіть датасет.
    - Запустіть training, логуючи результат у wandb.
    - Валідуйте модель.

5. **minio-storage**
    - Збережіть модель у minio з тегом-версією.

6. **triton-inference / ray-inference**
    - Розгорніть модель для inference на production-ready сервері.

7. **backend (fastAPI) та gradio-web**
    - Підніміть API й веб-інтерфейс.
    - Забезпечте зручне порівняння результатів моделей та інтеграцію з інфраструктурою.

8. **dagster-pipeline**
    - Реалізуйте оркестрацію всіх етапів, контроль дріфта, логування, переобучення.

#### 4. Примітки щодо використання Python та бібліотек
- Використовувати Python 3.12.
- Бібліотеки — максимально актуальні без конфліктів сумісності.

#### 5. Структура папок
``` 
project/
│
├── crawler/
│   └── ...
├── dataset-labeling/
├── gemini-integration/
├── yolov11-train/
├── minio-storage/
├── triton-inference/
├── ray-inference/
├── backend/
├── gradio-web/
└── dagster-pipeline/
```
#### 6. Рекомендації
- Кожен модуль оформлювати як окремий пакет із README, залежностями (`requirements.txt`).
- Описати типові сценарії запуску (Makefile, bash scripts, CLI).
- Всі дані/артефакти логувати та версіонувати.
- Протестувати повний flow: додавання зображення → розмітка → навчання → сервіс інференсу → перевірка на вебі.

Якщо потрібно структурований технічний документ (на кшталт SRS або інструкцій), дайте знати — надішлю приклад або шаблон для вашого випадку!
